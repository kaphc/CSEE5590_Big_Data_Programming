{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "#import numpy\n",
    "# Load training data\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "# from pyspark.python.pyspark.shell import spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+----+---+---+\n",
      "|  1|     3|  5| 10|  11| 12| 13|\n",
      "+---+------+---+---+----+---+---+\n",
      "| 39| 77516| 13|  1|2174|  0| 40|\n",
      "| 50| 83311| 13|  1|   0|  0| 13|\n",
      "| 38|215646|  9|  1|   0|  0| 40|\n",
      "| 53|234721|  7|  1|   0|  0| 40|\n",
      "| 28|338409| 13|  2|   0|  0| 40|\n",
      "+---+------+---+---+----+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.load(\"adult_data.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 1: integer (nullable = true)\n",
      " |-- 3: integer (nullable = true)\n",
      " |-- 5: integer (nullable = true)\n",
      " |-- 10: integer (nullable = true)\n",
      " |-- 11: integer (nullable = true)\n",
      " |-- 12: integer (nullable = true)\n",
      " |-- 13: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Change column type\n",
    "data = data.withColumn(\"1\", data[\"1\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"3\", data[\"3\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"5\", data[\"5\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"10\", data[\"10\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"11\", data[\"11\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"12\", data[\"12\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"13\", data[\"13\"].cast(IntegerType()))\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+----+---+---+-----+\n",
      "|  1|     3|  5| 10|  11| 12| 13|label|\n",
      "+---+------+---+---+----+---+---+-----+\n",
      "| 39| 77516| 13|  1|2174|  0| 40|    1|\n",
      "| 50| 83311| 13|  1|   0|  0| 13|    1|\n",
      "| 38|215646|  9|  1|   0|  0| 40|    1|\n",
      "| 53|234721|  7|  1|   0|  0| 40|    1|\n",
      "| 28|338409| 13|  2|   0|  0| 40|    2|\n",
      "+---+------+---+---+----+---+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumn(\"label\", data['10'] - 0)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+----+---+---+-----+--------------------+\n",
      "|  1|     3|  5| 10|  11| 12| 13|label|            features|\n",
      "+---+------+---+---+----+---+---+-----+--------------------+\n",
      "| 39| 77516| 13|  1|2174|  0| 40|    1|[39.0,77516.0,13....|\n",
      "| 50| 83311| 13|  1|   0|  0| 13|    1|[50.0,83311.0,13....|\n",
      "| 38|215646|  9|  1|   0|  0| 40|    1|[38.0,215646.0,9....|\n",
      "| 53|234721|  7|  1|   0|  0| 40|    1|[53.0,234721.0,7....|\n",
      "| 28|338409| 13|  2|   0|  0| 40|    2|[28.0,338409.0,13...|\n",
      "+---+------+---+---+----+---+---+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assem = VectorAssembler(inputCols=data.columns[0:7], outputCol='features')\n",
    "data = assem.transform(data)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "train,test = data.randomSplit([0.6, 0.4], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  1|    3|  5| 10|  11| 12| 13|label|            features|       rawPrediction|         probability|prediction|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "| 17|19752|  7|  2|   0|  0| 25|    2|[17.0,19752.0,7.0...|[-603.83024152897...|[3.55017080576790...|       1.0|\n",
      "| 17|24090|  9|  2|   0|  0| 35|    2|[17.0,24090.0,9.0...|[-741.82504306404...|[1.30388265806149...|       1.0|\n",
      "| 17|25051|  6|  1|   0|  0| 16|    1|[17.0,25051.0,6.0...|[-547.62221373539...|[8.55480582189268...|       1.0|\n",
      "| 17|29571|  8|  1|   0|  0| 15|    1|[17.0,29571.0,8.0...|[-594.41135826275...|[4.22658921812652...|       1.0|\n",
      "| 17|31007|  6|  2|   0|  0| 30|    2|[17.0,31007.0,6.0...|[-724.46084085428...|[6.78632746005661...|       1.0|\n",
      "| 17|32607|  6|  1|   0|  0| 20|    1|[17.0,32607.0,6.0...|[-640.64253400357...|[1.15328171287486...|       1.0|\n",
      "| 17|34019|  6|  1|   0|  0| 20|    1|[17.0,34019.0,6.0...|[-651.73053151831...|[6.37226542496344...|       1.0|\n",
      "| 17|47199|  7|  2|   0|  0| 24|    2|[17.0,47199.0,7.0...|[-810.94165940269...|[4.09823298203926...|       1.0|\n",
      "| 17|47407|  7|  1|   0|  0| 10|    1|[17.0,47407.0,7.0...|[-682.50701010310...|[7.20402670691894...|       1.0|\n",
      "| 17|47425|  7|  2|   0|  0| 15|    2|[17.0,47425.0,7.0...|[-736.92422009277...|[5.97762415001099...|       1.0|\n",
      "| 17|48751|  7|  2|   0|  0| 40|    2|[17.0,48751.0,7.0...|[-957.87062833477...|[9.44173491171634...|       1.0|\n",
      "| 17|51939|  7|  2|   0|  0| 15|    2|[17.0,51939.0,7.0...|[-772.37126030632...|[3.62335422568621...|       1.0|\n",
      "| 17|52967|  6|  2|   0|  0|  6|    2|[17.0,52967.0,6.0...|[-694.79350901279...|[2.84419394135382...|       1.0|\n",
      "| 17|56536|  7|  2|1055|  0| 18|    2|[17.0,56536.0,7.0...|[-6097.5873539652...|[1.0,8.4472058747...|       0.0|\n",
      "| 17|57723|  7|  1|   0|  0| 30|    1|[17.0,57723.0,7.0...|[-931.94234816865...|[2.61992594168364...|       1.0|\n",
      "| 17|61838|  6|  1|   0|  0| 40|    1|[17.0,61838.0,6.0...|[-1038.6114931677...|[2.39621595957688...|       1.0|\n",
      "| 17|63734|  6|  1|   0|  0| 20|    1|[17.0,63734.0,6.0...|[-885.07319876367...|[1.96377114784332...|       1.0|\n",
      "| 17|65368|  7|  2|   0|  0| 12|    2|[17.0,65368.0,7.0...|[-852.56097799572...|[8.49754512410958...|       1.0|\n",
      "| 17|73338|  7|  1|   0|  0| 20|    1|[17.0,73338.0,7.0...|[-970.34859724753...|[8.39575438208398...|       1.0|\n",
      "| 17|86786|  6|  2|   0|  0| 40|    2|[17.0,86786.0,6.0...|[-1246.6895029419...|[1.49369880939272...|       1.0|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.5782105903834449\n"
     ]
    }
   ],
   "source": [
    "# create the trainer and set its parameters\n",
    "nb1 = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model1 = nb1.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model1.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  1|    3|  5| 10|  11| 12| 13|label|            features|       rawPrediction|         probability|prediction|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "| 17|19752|  7|  2|   0|  0| 25|    2|[17.0,19752.0,7.0...|[-603.82833255900...|[3.54425060120333...|       1.0|\n",
      "| 17|24090|  9|  2|   0|  0| 35|    2|[17.0,24090.0,9.0...|[-741.82292742258...|[1.30136607200351...|       1.0|\n",
      "| 17|25051|  6|  1|   0|  0| 16|    1|[17.0,25051.0,6.0...|[-547.62132541304...|[8.54402615287241...|       1.0|\n",
      "| 17|29571|  8|  1|   0|  0| 15|    1|[17.0,29571.0,8.0...|[-594.41044627901...|[4.22120922120825...|       1.0|\n",
      "| 17|31007|  6|  2|   0|  0| 30|    2|[17.0,31007.0,6.0...|[-724.45916112928...|[6.77654354208634...|       1.0|\n",
      "| 17|32607|  6|  1|   0|  0| 20|    1|[17.0,32607.0,6.0...|[-640.64174307001...|[1.15193184728851...|       1.0|\n",
      "| 17|34019|  6|  1|   0|  0| 20|    1|[17.0,34019.0,6.0...|[-651.72977095405...|[6.36502000496325...|       1.0|\n",
      "| 17|47199|  7|  2|   0|  0| 24|    2|[17.0,47199.0,7.0...|[-810.94035704434...|[4.09415310679917...|       1.0|\n",
      "| 17|47407|  7|  1|   0|  0| 10|    1|[17.0,47407.0,7.0...|[-682.50663172273...|[7.19921588862550...|       1.0|\n",
      "| 17|47425|  7|  2|   0|  0| 15|    2|[17.0,47425.0,7.0...|[-736.92306912803...|[5.97290642254729...|       1.0|\n",
      "| 17|48751|  7|  2|   0|  0| 40|    2|[17.0,48751.0,7.0...|[-957.86909885407...|[9.42931052199523...|       1.0|\n",
      "| 17|51939|  7|  2|   0|  0| 15|    2|[17.0,51939.0,7.0...|[-772.37020642871...|[3.62088197973504...|       1.0|\n",
      "| 17|52967|  6|  2|   0|  0|  6|    2|[17.0,52967.0,6.0...|[-694.79269235772...|[2.84309659778580...|       1.0|\n",
      "| 17|56536|  7|  2|1055|  0| 18|    2|[17.0,56536.0,7.0...|[-6097.5858205192...|[1.0,8.4675698472...|       0.0|\n",
      "| 17|57723|  7|  1|   0|  0| 30|    1|[17.0,57723.0,7.0...|[-931.94186603640...|[2.61764652262903...|       1.0|\n",
      "| 17|61838|  6|  1|   0|  0| 40|    1|[17.0,61838.0,6.0...|[-1038.6110053062...|[2.39400008659202...|       1.0|\n",
      "| 17|63734|  6|  1|   0|  0| 20|    1|[17.0,63734.0,6.0...|[-885.07307730976...|[1.96292043515726...|       1.0|\n",
      "| 17|65368|  7|  2|   0|  0| 12|    2|[17.0,65368.0,7.0...|[-852.56026179338...|[8.49502022012697...|       1.0|\n",
      "| 17|73338|  7|  1|   0|  0| 20|    1|[17.0,73338.0,7.0...|[-970.34861377700...|[8.39343071701313...|       1.0|\n",
      "| 17|86786|  6|  2|   0|  0| 40|    2|[17.0,86786.0,6.0...|[-1246.6888600977...|[1.49318504988566...|       1.0|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.5782105903834449\n"
     ]
    }
   ],
   "source": [
    "# create the trainer and set its parameters\n",
    "nb2 = NaiveBayes(smoothing=10.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model2 = nb2.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model2.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+---+----+---+---+-----+--------------------+-----------------+-------------+----------+\n",
      "|  1|    3|  5| 10|  11| 12| 13|label|            features|    rawPrediction|  probability|prediction|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+-----------------+-------------+----------+\n",
      "| 17|19752|  7|  2|   0|  0| 25|    2|[17.0,19752.0,7.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|24090|  9|  2|   0|  0| 35|    2|[17.0,24090.0,9.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|25051|  6|  1|   0|  0| 16|    1|[17.0,25051.0,6.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|29571|  8|  1|   0|  0| 15|    1|[17.0,29571.0,8.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|31007|  6|  2|   0|  0| 30|    2|[17.0,31007.0,6.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|32607|  6|  1|   0|  0| 20|    1|[17.0,32607.0,6.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|34019|  6|  1|   0|  0| 20|    1|[17.0,34019.0,6.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|47199|  7|  2|   0|  0| 24|    2|[17.0,47199.0,7.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|47407|  7|  1|   0|  0| 10|    1|[17.0,47407.0,7.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|47425|  7|  2|   0|  0| 15|    2|[17.0,47425.0,7.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|48751|  7|  2|   0|  0| 40|    2|[17.0,48751.0,7.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|51939|  7|  2|   0|  0| 15|    2|[17.0,51939.0,7.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|52967|  6|  2|   0|  0|  6|    2|[17.0,52967.0,6.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|56536|  7|  2|1055|  0| 18|    2|[17.0,56536.0,7.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|57723|  7|  1|   0|  0| 30|    1|[17.0,57723.0,7.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|61838|  6|  1|   0|  0| 40|    1|[17.0,61838.0,6.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|63734|  6|  1|   0|  0| 20|    1|[17.0,63734.0,6.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|65368|  7|  2|   0|  0| 12|    2|[17.0,65368.0,7.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|73338|  7|  1|   0|  0| 20|    1|[17.0,73338.0,7.0...|[0.0,13008.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|86786|  6|  2|   0|  0| 40|    2|[17.0,86786.0,6.0...| [0.0,0.0,6409.0]|[0.0,0.0,1.0]|       2.0|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+-----------------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb3 = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# train the model\n",
    "model3 = nb3.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model3.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  1|    3|  5| 10|  11| 12| 13|label|            features|       rawPrediction|         probability|prediction|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "| 17|19752|  7|  2|   0|  0| 25|    2|[17.0,19752.0,7.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|24090|  9|  2|   0|  0| 35|    2|[17.0,24090.0,9.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|25051|  6|  1|   0|  0| 16|    1|[17.0,25051.0,6.0...|[0.0,9.4271755725...|[0.0,0.9427175572...|       1.0|\n",
      "| 17|29571|  8|  1|   0|  0| 15|    1|[17.0,29571.0,8.0...|[0.0,9.4271755725...|[0.0,0.9427175572...|       1.0|\n",
      "| 17|31007|  6|  2|   0|  0| 30|    2|[17.0,31007.0,6.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|32607|  6|  1|   0|  0| 20|    1|[17.0,32607.0,6.0...|[0.0,9.4271755725...|[0.0,0.9427175572...|       1.0|\n",
      "| 17|34019|  6|  1|   0|  0| 20|    1|[17.0,34019.0,6.0...|[0.0,9.4271755725...|[0.0,0.9427175572...|       1.0|\n",
      "| 17|47199|  7|  2|   0|  0| 24|    2|[17.0,47199.0,7.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|47407|  7|  1|   0|  0| 10|    1|[17.0,47407.0,7.0...|[0.0,9.4271755725...|[0.0,0.9427175572...|       1.0|\n",
      "| 17|47425|  7|  2|   0|  0| 15|    2|[17.0,47425.0,7.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|48751|  7|  2|   0|  0| 40|    2|[17.0,48751.0,7.0...|      [0.0,0.0,10.0]|       [0.0,0.0,1.0]|       2.0|\n",
      "| 17|51939|  7|  2|   0|  0| 15|    2|[17.0,51939.0,7.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|52967|  6|  2|   0|  0|  6|    2|[17.0,52967.0,6.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|56536|  7|  2|1055|  0| 18|    2|[17.0,56536.0,7.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|57723|  7|  1|   0|  0| 30|    1|[17.0,57723.0,7.0...|[0.0,9.4271755725...|[0.0,0.9427175572...|       1.0|\n",
      "| 17|61838|  6|  1|   0|  0| 40|    1|[17.0,61838.0,6.0...|      [0.0,10.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "| 17|63734|  6|  1|   0|  0| 20|    1|[17.0,63734.0,6.0...|[0.0,9.4271755725...|[0.0,0.9427175572...|       1.0|\n",
      "| 17|65368|  7|  2|   0|  0| 12|    2|[17.0,65368.0,7.0...|[0.0,0.4271755725...|[0.0,0.0427175572...|       2.0|\n",
      "| 17|73338|  7|  1|   0|  0| 20|    1|[17.0,73338.0,7.0...|[0.0,9.4271755725...|[0.0,0.9427175572...|       1.0|\n",
      "| 17|86786|  6|  2|   0|  0| 40|    2|[17.0,86786.0,6.0...|      [0.0,0.0,10.0]|       [0.0,0.0,1.0]|       2.0|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb3 = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
    "\n",
    "# train the model\n",
    "model3 = nb3.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model3.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  1|    3|  5| 10|  11| 12| 13|label|            features|       rawPrediction|         probability|prediction|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "| 17|19752|  7|  2|   0|  0| 25|    2|[17.0,19752.0,7.0...|[0.0,5.5219912822...|[0.0,0.0552199128...|       2.0|\n",
      "| 17|24090|  9|  2|   0|  0| 35|    2|[17.0,24090.0,9.0...|[0.0,4.2688654979...|[0.0,0.0426886549...|       2.0|\n",
      "| 17|25051|  6|  1|   0|  0| 16|    1|[17.0,25051.0,6.0...|[0.0,94.521991282...|[0.0,0.9452199128...|       1.0|\n",
      "| 17|29571|  8|  1|   0|  0| 15|    1|[17.0,29571.0,8.0...|[0.0,94.209548863...|[0.0,0.9420954886...|       1.0|\n",
      "| 17|31007|  6|  2|   0|  0| 30|    2|[17.0,31007.0,6.0...|[0.0,5.5219912822...|[0.0,0.0552199128...|       2.0|\n",
      "| 17|32607|  6|  1|   0|  0| 20|    1|[17.0,32607.0,6.0...|[0.0,94.521991282...|[0.0,0.9452199128...|       1.0|\n",
      "| 17|34019|  6|  1|   0|  0| 20|    1|[17.0,34019.0,6.0...|[0.0,94.521991282...|[0.0,0.9452199128...|       1.0|\n",
      "| 17|47199|  7|  2|   0|  0| 24|    2|[17.0,47199.0,7.0...|[0.0,5.5219912822...|[0.0,0.0552199128...|       2.0|\n",
      "| 17|47407|  7|  1|   0|  0| 10|    1|[17.0,47407.0,7.0...|[0.0,94.521991282...|[0.0,0.9452199128...|       1.0|\n",
      "| 17|47425|  7|  2|   0|  0| 15|    2|[17.0,47425.0,7.0...|[0.0,5.5219912822...|[0.0,0.0552199128...|       2.0|\n",
      "| 17|48751|  7|  2|   0|  0| 40|    2|[17.0,48751.0,7.0...|[0.0,5.8123755367...|[0.0,0.0581237553...|       2.0|\n",
      "| 17|51939|  7|  2|   0|  0| 15|    2|[17.0,51939.0,7.0...|[0.0,5.5219912822...|[0.0,0.0552199128...|       2.0|\n",
      "| 17|52967|  6|  2|   0|  0|  6|    2|[17.0,52967.0,6.0...|[0.0,5.5219912822...|[0.0,0.0552199128...|       2.0|\n",
      "| 17|56536|  7|  2|1055|  0| 18|    2|[17.0,56536.0,7.0...|[0.0,5.5219912822...|[0.0,0.0552199128...|       2.0|\n",
      "| 17|57723|  7|  1|   0|  0| 30|    1|[17.0,57723.0,7.0...|[0.0,94.521991282...|[0.0,0.9452199128...|       1.0|\n",
      "| 17|61838|  6|  1|   0|  0| 40|    1|[17.0,61838.0,6.0...|[0.0,96.812375536...|[0.0,0.9681237553...|       1.0|\n",
      "| 17|63734|  6|  1|   0|  0| 20|    1|[17.0,63734.0,6.0...|[0.0,94.521991282...|[0.0,0.9452199128...|       1.0|\n",
      "| 17|65368|  7|  2|   0|  0| 12|    2|[17.0,65368.0,7.0...|[0.0,5.5219912822...|[0.0,0.0552199128...|       2.0|\n",
      "| 17|73338|  7|  1|   0|  0| 20|    1|[17.0,73338.0,7.0...|[0.0,94.521991282...|[0.0,0.9452199128...|       1.0|\n",
      "| 17|86786|  6|  2|   0|  0| 40|    2|[17.0,86786.0,6.0...|[0.0,5.8123755367...|[0.0,0.0581237553...|       2.0|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb3 = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "\n",
    "# train the model\n",
    "model3 = nb3.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model3.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+---+----+---+---+-----+--------------------+-------------+-------------+----------+\n",
      "|  1|    3|  5| 10|  11| 12| 13|label|            features|rawPrediction|  probability|prediction|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+-------------+-------------+----------+\n",
      "| 17|19752|  7|  2|   0|  0| 25|    2|[17.0,19752.0,7.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|24090|  9|  2|   0|  0| 35|    2|[17.0,24090.0,9.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|25051|  6|  1|   0|  0| 16|    1|[17.0,25051.0,6.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|29571|  8|  1|   0|  0| 15|    1|[17.0,29571.0,8.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|31007|  6|  2|   0|  0| 30|    2|[17.0,31007.0,6.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|32607|  6|  1|   0|  0| 20|    1|[17.0,32607.0,6.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|34019|  6|  1|   0|  0| 20|    1|[17.0,34019.0,6.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|47199|  7|  2|   0|  0| 24|    2|[17.0,47199.0,7.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|47407|  7|  1|   0|  0| 10|    1|[17.0,47407.0,7.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|47425|  7|  2|   0|  0| 15|    2|[17.0,47425.0,7.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|48751|  7|  2|   0|  0| 40|    2|[17.0,48751.0,7.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|51939|  7|  2|   0|  0| 15|    2|[17.0,51939.0,7.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|52967|  6|  2|   0|  0|  6|    2|[17.0,52967.0,6.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|56536|  7|  2|1055|  0| 18|    2|[17.0,56536.0,7.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|57723|  7|  1|   0|  0| 30|    1|[17.0,57723.0,7.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|61838|  6|  1|   0|  0| 40|    1|[17.0,61838.0,6.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|63734|  6|  1|   0|  0| 20|    1|[17.0,63734.0,6.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|65368|  7|  2|   0|  0| 12|    2|[17.0,65368.0,7.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "| 17|73338|  7|  1|   0|  0| 20|    1|[17.0,73338.0,7.0...|[0.0,1.0,0.0]|[0.0,1.0,0.0]|       1.0|\n",
      "| 17|86786|  6|  2|   0|  0| 40|    2|[17.0,86786.0,6.0...|[0.0,0.0,1.0]|[0.0,0.0,1.0]|       2.0|\n",
      "+---+-----+---+---+----+---+---+-----+--------------------+-------------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb3 = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=1)\n",
    "\n",
    "# train the model\n",
    "model3 = nb3.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model3.transform(test)\n",
    "predictions.show()\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-----+----+----+----+---+----+----+---+---+----+---+---+\n",
      "|  0|  1|   2|    3|   4|   5|   6|  7|   8|   9| 10| 11|  12| 13| 14|\n",
      "+---+---+----+-----+----+----+----+---+----+----+---+---+----+---+---+\n",
      "|  3|  1|88.6|168.8|64.1|48.8|2548|130|3.47|2.68|  9|111|5000| 21| 27|\n",
      "|  3|  1|88.6|168.8|64.1|48.8|2548|130|3.47|2.68|  9|111|5000| 21| 27|\n",
      "|  1|  1|94.5|171.2|65.5|52.4|2823|152|2.68|3.47|  9|154|5000| 19| 26|\n",
      "|  2|  1|99.8|176.6|66.2|54.3|2337|109|3.19| 3.4| 10|102|5500| 24| 30|\n",
      "|  2|  1|99.4|176.6|66.4|54.3|2824|136|3.19| 3.4|  8|115|5500| 18| 22|\n",
      "+---+---+----+-----+----+----+----+---+----+----+---+---+----+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.load(\"imports-85_data.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- 1: integer (nullable = true)\n",
      " |-- 2: integer (nullable = true)\n",
      " |-- 3: integer (nullable = true)\n",
      " |-- 4: integer (nullable = true)\n",
      " |-- 5: integer (nullable = true)\n",
      " |-- 6: integer (nullable = true)\n",
      " |-- 7: integer (nullable = true)\n",
      " |-- 8: integer (nullable = true)\n",
      " |-- 9: integer (nullable = true)\n",
      " |-- 10: integer (nullable = true)\n",
      " |-- 11: integer (nullable = true)\n",
      " |-- 12: integer (nullable = true)\n",
      " |-- 13: integer (nullable = true)\n",
      " |-- 14: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# Change column type\n",
    "data = data.withColumn(\"0\", data[\"0\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"1\", data[\"1\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"2\", data[\"2\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"4\", data[\"4\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"3\", data[\"3\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"5\", data[\"5\"].cast(IntegerType()))\n",
    "\n",
    "data = data.withColumn(\"6\", data[\"6\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"7\", data[\"7\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"8\", data[\"8\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"9\", data[\"9\"].cast(IntegerType()))\n",
    "\n",
    "\n",
    "data = data.withColumn(\"10\", data[\"10\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"11\", data[\"11\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"12\", data[\"12\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"13\", data[\"13\"].cast(IntegerType()))\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+----+---+---+---+---+---+----+---+---+-----+\n",
      "|  0|  1|  2|  3|  4|  5|   6|  7|  8|  9| 10| 11|  12| 13| 14|label|\n",
      "+---+---+---+---+---+---+----+---+---+---+---+---+----+---+---+-----+\n",
      "|  3|  1| 88|168| 64| 48|2548|130|  3|  2|  9|111|5000| 21| 27| 27.0|\n",
      "|  3|  1| 88|168| 64| 48|2548|130|  3|  2|  9|111|5000| 21| 27| 27.0|\n",
      "|  1|  1| 94|171| 65| 52|2823|152|  2|  3|  9|154|5000| 19| 26| 26.0|\n",
      "|  2|  1| 99|176| 66| 54|2337|109|  3|  3| 10|102|5500| 24| 30| 30.0|\n",
      "|  2|  1| 99|176| 66| 54|2824|136|  3|  3|  8|115|5500| 18| 22| 22.0|\n",
      "+---+---+---+---+---+---+----+---+---+---+---+---+----+---+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumn(\"label\", data['14'] - 0)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+----+---+---+---+---+---+----+---+---+-----+--------------------+\n",
      "|  0|  1|  2|  3|  4|  5|   6|  7|  8|  9| 10| 11|  12| 13| 14|label|            features|\n",
      "+---+---+---+---+---+---+----+---+---+---+---+---+----+---+---+-----+--------------------+\n",
      "|  3|  1| 88|168| 64| 48|2548|130|  3|  2|  9|111|5000| 21| 27| 27.0|[3.0,1.0,88.0,168...|\n",
      "|  3|  1| 88|168| 64| 48|2548|130|  3|  2|  9|111|5000| 21| 27| 27.0|[3.0,1.0,88.0,168...|\n",
      "|  1|  1| 94|171| 65| 52|2823|152|  2|  3|  9|154|5000| 19| 26| 26.0|[1.0,1.0,94.0,171...|\n",
      "|  2|  1| 99|176| 66| 54|2337|109|  3|  3| 10|102|5500| 24| 30| 30.0|[2.0,1.0,99.0,176...|\n",
      "|  2|  1| 99|176| 66| 54|2824|136|  3|  3|  8|115|5500| 18| 22| 22.0|[2.0,1.0,99.0,176...|\n",
      "+---+---+---+---+---+---+----+---+---+---+---+---+----+---+---+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assem = VectorAssembler(inputCols=data.columns[0:14], outputCol='features')\n",
    "data = assem.transform(data)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "train,test = data.randomSplit([0.6, 0.4], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-----+----+----+----+---+----+----+---+---+----+---+---+\n",
      "|  0|  1|   2|    3|   4|   5|   6|  7|   8|   9| 10| 11|  12| 13| 14|\n",
      "+---+---+----+-----+----+----+----+---+----+----+---+---+----+---+---+\n",
      "|  3|  1|88.6|168.8|64.1|48.8|2548|130|3.47|2.68|  9|111|5000| 21| 27|\n",
      "|  3|  1|88.6|168.8|64.1|48.8|2548|130|3.47|2.68|  9|111|5000| 21| 27|\n",
      "|  1|  1|94.5|171.2|65.5|52.4|2823|152|2.68|3.47|  9|154|5000| 19| 26|\n",
      "|  2|  1|99.8|176.6|66.2|54.3|2337|109|3.19| 3.4| 10|102|5500| 24| 30|\n",
      "|  2|  1|99.4|176.6|66.4|54.3|2824|136|3.19| 3.4|  8|115|5500| 18| 22|\n",
      "+---+---+----+-----+----+----+----+---+----+----+---+---+----+---+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- 0: integer (nullable = true)\n",
      " |-- 1: integer (nullable = true)\n",
      " |-- 2: integer (nullable = true)\n",
      " |-- 3: integer (nullable = true)\n",
      " |-- 4: integer (nullable = true)\n",
      " |-- 5: integer (nullable = true)\n",
      " |-- 6: integer (nullable = true)\n",
      " |-- 7: integer (nullable = true)\n",
      " |-- 8: integer (nullable = true)\n",
      " |-- 9: integer (nullable = true)\n",
      " |-- 10: integer (nullable = true)\n",
      " |-- 11: integer (nullable = true)\n",
      " |-- 12: integer (nullable = true)\n",
      " |-- 13: integer (nullable = true)\n",
      " |-- 14: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Field \"features\" does not exist.\\nAvailable fields: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\kaphc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kaphc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1459.fit.\n: java.lang.IllegalArgumentException: Field \"features\" does not exist.\nAvailable fields: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14\r\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\r\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\r\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\r\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\r\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:273)\r\n\tat org.apache.spark.ml.util.SchemaUtils$.checkColumnType(SchemaUtils.scala:41)\r\n\tat org.apache.spark.ml.PredictorParams$class.validateAndTransformSchema(Predictor.scala:51)\r\n\tat org.apache.spark.ml.regression.LinearRegression.org$apache$spark$ml$regression$LinearRegressionParams$$super$validateAndTransformSchema(LinearRegression.scala:177)\r\n\tat org.apache.spark.ml.regression.LinearRegressionParams$class.validateAndTransformSchema(LinearRegression.scala:120)\r\n\tat org.apache.spark.ml.regression.LinearRegression.validateAndTransformSchema(LinearRegression.scala:177)\r\n\tat org.apache.spark.ml.Predictor.transformSchema(Predictor.scala:144)\r\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:100)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5d31b1c3b546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mlrModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Print the coefficients and intercept for linear regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kaphc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mc:\\users\\kaphc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kaphc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \"\"\"\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kaphc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kaphc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: 'Field \"features\" does not exist.\\nAvailable fields: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14'"
     ]
    }
   ],
   "source": [
    "data = spark.read.load(\"imports-85_data.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "data.show(5)\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Change column type\n",
    "data = data.withColumn(\"0\", data[\"0\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"1\", data[\"1\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"2\", data[\"2\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"4\", data[\"4\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"3\", data[\"3\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"5\", data[\"5\"].cast(IntegerType()))\n",
    "\n",
    "data = data.withColumn(\"6\", data[\"6\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"7\", data[\"7\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"8\", data[\"8\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"9\", data[\"9\"].cast(IntegerType()))\n",
    "\n",
    "\n",
    "data = data.withColumn(\"10\", data[\"10\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"11\", data[\"11\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"12\", data[\"12\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"13\", data[\"13\"].cast(IntegerType()))\n",
    "\n",
    "data.printSchema()\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(data)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
